{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "\n",
        "# Data preparation\n",
        "def load_data(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "      try:\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is None:\n",
        "          print(f\"Unable to read image: {os.path.join(folder, filename)}\")\n",
        "          continue\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "        img = cv2.resize(img, (256, 256))  # Resize to a standard size\n",
        "        images.append(img)\n",
        "      except Exception as e:\n",
        "        print(f\"Error processing image: {os.path.join(folder, filename)} - {e}\")\n",
        "    return np.array(images)\n",
        "\n",
        "train_images = load_data('sample_data/Train')\n",
        "train_masks = load_data('sample_data/Result')\n",
        "test_images = load_data('sample_data/Test')\n",
        "test_masks = load_data('sample_data/Test_Result')\n",
        "\n",
        "train_masks = train_masks[..., 0:1]\n",
        "test_masks = test_masks[..., 0:1]\n",
        "\n",
        "# Verify shapes\n",
        "print(\"Train Images Shape:\", train_images.shape)\n",
        "print(\"Train Masks Shape:\", train_masks.shape)\n",
        "print(\"Test Images Shape:\", test_images.shape)\n",
        "print(\"Test Masks Shape:\", test_masks.shape)\n",
        "\n",
        "# Normalize input data\n",
        "train_images = train_images.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "train_masks = train_masks.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "test_images = test_images.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "test_masks = test_masks.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "# Verify shapes after normalization\n",
        "print(\"Train Images Shape (after normalization):\", train_images.shape)\n",
        "print(\"Train Masks Shape (after normalization):\", train_masks.shape)\n",
        "print(\"Test Images Shape (after normalization):\", test_images.shape)\n",
        "print(\"Test Masks Shape (after normalization):\", test_masks.shape)\n",
        "\n",
        "\n",
        "def unet_model(input_shape):\n",
        "  inputs = Input(input_shape)\n",
        "\n",
        "  # Encoder\n",
        "  conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "  conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "  conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "  conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
        "  conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "  # Bottom/Center\n",
        "  conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
        "  conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "  # Decoder\n",
        "  up6 = Conv2D(512, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv5))\n",
        "  merge6 = concatenate([conv4, up6], axis=3)\n",
        "  conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
        "  conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "  up7 = Conv2D(256, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
        "  merge7 = concatenate([conv3, up7], axis=3)\n",
        "  conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
        "  conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
        "  up8 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv7))\n",
        "\n",
        "  merge8 = concatenate([conv2, up8], axis=3)\n",
        "  conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
        "  conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
        "  up9 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv8))\n",
        "\n",
        "  merge9 = concatenate([conv1, up9], axis=3)\n",
        "  conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
        "  conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
        "\n",
        "  # Output\n",
        "  outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "  return model\n",
        "\n",
        "model = unet_model((256, 256, 3))\n",
        "print(model.output_shape)\n",
        "\n",
        "# Model training\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_masks, epochs=10, batch_size=8, validation_split=0.2)\n",
        "\n",
        "# Model evaluation\n",
        "train_loss, train_acc = model.evaluate(train_images, train_masks)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_masks)\n",
        "print(f'Training Loss: {train_loss}, Accuracy: {train_acc}')\n",
        "print(f'Testing Loss: {test_loss}, Accuracy: {test_acc}')\n",
        "\n",
        "def segment_images(images):\n",
        "    segmented_images = []\n",
        "    for img in images:\n",
        "      # Apply segmentation model\n",
        "      segmented_img = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "      segmented_img = (segmented_img > 0.5).astype(np.uint8) * 255  # Thresholding\n",
        "      segmented_images.append(segmented_img)\n",
        "\n",
        "\n",
        "    # Convert the segmented images to 3-channel images\n",
        "    for i in range(len(segmented_images)):\n",
        "      # Create a white background image with the same shape as the original image\n",
        "      white_bg_img = np.ones_like(test_images[i]) * 255\n",
        "      white_bg_img_gray = cv2.cvtColor(white_bg_img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "      thresholded_img_rgb = cv2.cvtColor(segmented_images[i], cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "      # Set the pixels corresponding to the segmented glasses to black\n",
        "      white_bg_img_gray[thresholded_img_rgb[:, :, 0] == 255] = 0\n",
        "\n",
        "    # Save the segmented images\n",
        "    for i, img in enumerate(segmented_images):\n",
        "      cv2.imwrite(f'segmented_image_{i}.jpg', img)\n",
        "\n",
        "    return segmented_images\n",
        "\n",
        "segmented_test_images = segment_images(test_images)"
      ],
      "metadata": {
        "id": "UYJ6Tpzlv6KG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "23829e0b-258f-488e-a1b2-865108b8579e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Images Shape: (8, 256, 256, 3)\n",
            "Train Masks Shape: (8, 256, 256, 1)\n",
            "Test Images Shape: (8, 256, 256, 3)\n",
            "Test Masks Shape: (8, 256, 256, 1)\n",
            "Train Images Shape (after normalization): (8, 256, 256, 3)\n",
            "Train Masks Shape (after normalization): (8, 256, 256, 1)\n",
            "Test Images Shape (after normalization): (8, 256, 256, 3)\n",
            "Test Masks Shape (after normalization): (8, 256, 256, 1)\n",
            "(None, 256, 256, 1)\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 45s 45s/step - loss: 0.6737 - accuracy: 0.9252 - val_loss: 0.4568 - val_accuracy: 0.9482\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 40s 40s/step - loss: 0.4660 - accuracy: 0.9329 - val_loss: 11.5509 - val_accuracy: 0.9482\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 41s 41s/step - loss: 17.5464 - accuracy: 0.9329 - val_loss: 0.2617 - val_accuracy: 0.9482\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 41s 41s/step - loss: 0.2843 - accuracy: 0.9329 - val_loss: 0.3611 - val_accuracy: 0.9482\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 41s 41s/step - loss: 0.3755 - accuracy: 0.9329 - val_loss: 0.3740 - val_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 39s 39s/step - loss: 0.3876 - accuracy: 0.9329 - val_loss: 0.3575 - val_accuracy: 0.9482\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 41s 41s/step - loss: 0.3721 - accuracy: 0.9329 - val_loss: 0.3200 - val_accuracy: 0.9482\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 40s 40s/step - loss: 0.3371 - accuracy: 0.9329 - val_loss: 0.2388 - val_accuracy: 0.9482\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 41s 41s/step - loss: 0.2630 - accuracy: 0.9329 - val_loss: 0.1914 - val_accuracy: 0.9482\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 41s 41s/step - loss: 0.2828 - accuracy: 0.9329 - val_loss: 0.1678 - val_accuracy: 0.9482\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.1952 - accuracy: 0.9367\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.1653 - accuracy: 0.9334\n",
            "Training Loss: 0.1951979696750641, Accuracy: 0.9366970062255859\n",
            "Testing Loss: 0.16530221700668335, Accuracy: 0.9334011077880859\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    }
  ]
}